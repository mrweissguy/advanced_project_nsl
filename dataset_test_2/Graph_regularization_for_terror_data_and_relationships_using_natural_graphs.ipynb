{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DADUIVuPIqYi"
   },
   "source": [
    "##### Copyright 2019 Google LLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Cu1zPez8Ip1S"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On data \n",
    "*Terrorists are linked to each other if they contact each other, use the same facility, are members of the same family, or belong to the same terrorist organization.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlIh_TPLI54s"
   },
   "source": [
    "# Graph regularization for document classification using natural graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pL9fF9FWI-Q1"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/neural_structured_learning/tutorials/graph_keras_mlp_cora\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/neural-structured-learning/blob/master/g3doc/tutorials/graph_keras_mlp_cora.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/neural-structured-learning/blob/master/g3doc/tutorials/graph_keras_mlp_cora.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJlN8oxhNGto"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Graph regularization is a specific technique under the broader paradigm of\n",
    "Neural Graph Learning\n",
    "([Bui et al., 2018](https://ai.google/research/pubs/pub46568.pdf)). The core\n",
    "idea is to train neural network models with a graph-regularized objective,\n",
    "harnessing both labeled and unlabeled data.\n",
    "\n",
    "In this tutorial, we will explore the use of graph regularization to classify\n",
    "documents that form a natural (organic) graph.\n",
    "\n",
    "The general recipe for creating a graph-regularized model using the Neural\n",
    "Structured Learning (NSL) framework is as follows:\n",
    "\n",
    "1.  Generate training data from the input graph and sample features. Nodes in\n",
    "    the graph correspond to samples and edges in the graph correspond to\n",
    "    similarity between pairs of samples. The resulting training data will\n",
    "    contain neighbor features in addition to the original node features.\n",
    "2.  Create a neural network as a base model using the `Keras` sequential,\n",
    "    functional, or subclass API.\n",
    "3.  Wrap the base model with the **`GraphRegularization`** wrapper class, which\n",
    "    is provided by the NSL framework, to create a new graph `Keras` model. This\n",
    "    new model will include a graph regularization loss as the regularization\n",
    "    term in its training objective.\n",
    "4.  Train and evaluate the graph `Keras` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nDOFbB34KY1R"
   },
   "source": [
    "## Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hgSLDi0SyBuO"
   },
   "source": [
    "1.  Select TensorFlow 2.x to create an interactive development environment with eager execution.\n",
    "2.  Install the Neural Structured Learning package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gh6K6Onyy5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu (from versions: none)\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for tensorflow-gpu\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  !pip install tensorflow-gpu>=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVnjPmOaQlnH"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet neural-structured-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0AiNrPJaX_Lb"
   },
   "source": [
    "## Dependencies and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sEamf-wZJkX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.0-rc1\n",
      "Eager mode:  True\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import neural_structured_learning as nsl\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Resets notebook state\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtbcGZ_N6Ll9"
   },
   "source": [
    "## Cora dataset\n",
    "\n",
    "The [Cora dataset](https://linqs.soe.ucsc.edu/data) is a citation graph where\n",
    "nodes represent machine learning papers and edges represent citations between\n",
    "pairs of papers. The task involved is document classification where the goal is\n",
    "to categorize each paper into one of 7 categories. In other words, this is a\n",
    "multi-class classification problem with 7 classes.\n",
    "\n",
    "### Graph\n",
    "\n",
    "The original graph is directed. However, for the purpose of this example, we\n",
    "consider the undirected version of this graph. So, if paper A cites paper B, we\n",
    "also consider paper B to have cited A. Although this is not necessarily true, in\n",
    "this example, we consider citations as a proxy for similarity, which is usually\n",
    "a commutative property.\n",
    "\n",
    "### Features\n",
    "\n",
    "Each paper in the input effectively contains 2 features:\n",
    "\n",
    "1.  **Words**: A dense, multi-hot bag-of-words representation of the text in the\n",
    "    paper. The vocabulary for the Cora dataset contains 1433 unique words. So,\n",
    "    the length of this feature is 1433, and the value at position 'i' is 0/1\n",
    "    indicating whether word 'i' in the vocabulary exists in the given paper or\n",
    "    not.\n",
    "\n",
    "2.  **Label**: A single integer representing the class ID (category) of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2-FVpVHEyIS"
   },
   "source": [
    "### Download the Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nSZjKqwE6Rn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to set locale category LC_NUMERIC to en_KR.\n",
      "Warning: Failed to set locale category LC_TIME to en_KR.\n",
      "Warning: Failed to set locale category LC_COLLATE to en_KR.\n",
      "Warning: Failed to set locale category LC_MONETARY to en_KR.\n",
      "Warning: Failed to set locale category LC_MESSAGES to en_KR.\n",
      "x TerrorAttack/\n",
      "x TerrorAttack/terrorist_attack.nodes\n",
      "x TerrorAttack/terrorist_attack_loc_org.edges\n",
      "x TerrorAttack/README\n",
      "x TerrorAttack/terrorist_attack_loc.edges\n",
      "x TerrorAttack/terrorist_attack.labels\n"
     ]
    }
   ],
   "source": [
    "!wget --quiet -P /tmp https://linqs-data.soe.ucsc.edu/public/lbc/TerrorAttack.tgz\n",
    "# !wget --quiet -P /tmp https://github.com/mrweissguy/nsl/tree/master/data/TerroristRel\n",
    "    \n",
    "    \n",
    "    \n",
    "# !tar -C /tmp -xvzf /tmp/cora.tgz\n",
    "!tar -C /tmp -xvzf /tmp/TerrorAttack.tgz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ylYP32_IoqZI"
   },
   "source": [
    "### Convert the Cora data to the NSL format\n",
    "\n",
    "In order to preprocess the Cora dataset and convert it to the format required by\n",
    "Neural Structured Learning, we will run the **'preprocess_cora_dataset.py'**\n",
    "script, which is included in the NSL github repository. This script does the\n",
    "following:\n",
    "\n",
    "1.  Generate neighbor features using the original node features and the graph.\n",
    "2.  Generate train and test data splits containing `tf.train.Example` instances.\n",
    "3.  Persist the resulting train and test data in the `TFRecord` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Myz01LVZQ8Uh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to set locale category LC_NUMERIC to en_KR.\n",
      "Warning: Failed to set locale category LC_TIME to en_KR.\n",
      "Warning: Failed to set locale category LC_COLLATE to en_KR.\n",
      "Warning: Failed to set locale category LC_MONETARY to en_KR.\n",
      "Warning: Failed to set locale category LC_MESSAGES to en_KR.\n",
      "--2019-11-05 09:11:20--  https://raw.githubusercontent.com/mrweissguy/nsl/master/dataset_test_2/preprocessing_terror_dataset.py?token=AKMVMPA3BIMHYWRBUIAZLOK5YEXHC\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.40.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.40.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12747 (12K) [text/plain]\n",
      "Saving to: ‘preprocessing_terror_dataset.py?token=AKMVMPA3BIMHYWRBUIAZLOK5YEXHC.1’\n",
      "\n",
      "preprocessing_terro 100%[===================>]  12.45K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2019-11-05 09:11:21 (296 KB/s) - ‘preprocessing_terror_dataset.py?token=AKMVMPA3BIMHYWRBUIAZLOK5YEXHC.1’ saved [12747/12747]\n",
      "\n",
      "preprocessing_terror_dataset.py:144: DeprecationWarning: 'U' mode is deprecated\n",
      "  with open(in_file, 'rU') as cora_content:\n",
      "Reading graph file: /tmp/TerrorAttack/terrorist_attack_loc.edges...\n",
      "Traceback (most recent call last):\n",
      "  File \"preprocessing_terror_dataset.py\", line 305, in <module>\n",
      "    app.run(main)\n",
      "  File \"/Users/johanweisshansen/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/Users/johanweisshansen/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"preprocessing_terror_dataset.py\", line 276, in main\n",
      "    graph = graph_utils.read_tsv_graph(FLAGS.input_cora_graph)\n",
      "  File \"/Users/johanweisshansen/anaconda3/lib/python3.7/site-packages/neural_structured_learning/tools/graph_utils.py\", line 127, in read_tsv_graph\n",
      "    add_edge(graph, edge)\n",
      "  File \"/Users/johanweisshansen/anaconda3/lib/python3.7/site-packages/neural_structured_learning/tools/graph_utils.py\", line 71, in add_edge\n",
      "    target = edge[1]\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "# !wget https://raw.githubusercontent.com/tensorflow/neural-structured-learning/master/neural_structured_learning/examples/preprocess/cora/preprocess_cora_dataset.py\n",
    "\n",
    "# !python preprocess_cora_dataset.py \\\n",
    "# --input_cora_content=/tmp/cora/cora.content \\\n",
    "# --input_cora_graph=/tmp/cora/cora.cites \\\n",
    "# --max_nbrs=5 \\\n",
    "# --output_train_data=/tmp/cora/train_merged_examples.tfr \\\n",
    "# --output_test_data=/tmp/cora/test_examples.tfr\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/mrweissguy/nsl/master/preprocessing_terror_dataset.py?token=AKMVMPGQOLZCWR6HB2NCZQK5XGN6U\n",
    "# https://raw.githubusercontent.com/mrweissguy/nsl/master/preprocessing_terror_dataset.py?token=AKMVMPEPFXMPBD5SDWZSSOS5XF6NO\n",
    "!wget https://raw.githubusercontent.com/mrweissguy/nsl/master/dataset_test_2/preprocessing_terror_dataset.py?token=AKMVMPA3BIMHYWRBUIAZLOK5YEXHC\n",
    "    \n",
    "  \n",
    "!python preprocessing_terror_dataset.py \\\n",
    "--input_cora_content=/tmp/TerrorAttack/terrorist_attack.nodes \\\n",
    "--input_cora_graph=/tmp/TerrorAttack/terrorist_attack_loc.edges \\\n",
    "--max_nbrs=5 \\\n",
    "--output_train_data=/tmp/TerrorAttack/train_merged_examples.tfr \\\n",
    "--output_test_data=/tmp/TerrorAttack/test_examples.tfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXoyHIdV5hEe"
   },
   "source": [
    "## Global variables\n",
    "\n",
    "The file paths to the train and test data are based on the command line flag\n",
    "values used to invoke the **'preprocess_cora_dataset.py'** script above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKAmzKIH6I9f"
   },
   "outputs": [],
   "source": [
    "# ### Experiment dataset\n",
    "# TRAIN_DATA_PATH = '/tmp/cora/train_merged_examples.tfr'\n",
    "# TEST_DATA_PATH = '/tmp/cora/test_examples.tfr'\n",
    "\n",
    "# ### Constants used to identify neighbor features in the input.\n",
    "# NBR_FEATURE_PREFIX = 'NL_nbr_'\n",
    "# NBR_WEIGHT_SUFFIX = '_weight'\n",
    "\n",
    "### Experiment dataset\n",
    "TRAIN_DATA_PATH = '/tmp/TerroristRel/train_merged_examples.tfr'\n",
    "TEST_DATA_PATH = '/tmp/TerroristRel/test_examples.tfr'\n",
    "\n",
    "### Constants used to identify neighbor features in the input.\n",
    "NBR_FEATURE_PREFIX = 'NL_nbr_'\n",
    "NBR_WEIGHT_SUFFIX = '_weight'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2gYWAqJqZ76I"
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "We will use an instance of `HParams` to inclue various hyperparameters and\n",
    "constants used for training and evaluation. We briefly describe each of them\n",
    "below:\n",
    "\n",
    "-   **num_classes**: There are a total 7 different classes\n",
    "\n",
    "-   **max_seq_length**: This is the size of the vocabulary and all instances in\n",
    "    the input have a dense multi-hot, bag-of-words representation. In other\n",
    "    words, a value of 1 for a word indicates that the word is present in the\n",
    "    input and a value of 0 indicates that it is not.\n",
    "\n",
    "-   **distance_type**: This is the distance metric used to regularize the sample\n",
    "    with its neighbors.\n",
    "\n",
    "-   **graph_regularization_multiplier**: This controls the relative weight of\n",
    "    the graph regularization term in the overall loss function.\n",
    "\n",
    "-   **num_neighbors**: The number of neighbors used for graph regularization.\n",
    "    This value has to be less than or equal to the `max_nbrs` command-line\n",
    "    argument used above when running `preprocess_cora_dataset.py`.\n",
    "\n",
    "-   **num_fc_units**: The number of fully connected layers in our neural\n",
    "    network.\n",
    "\n",
    "-   **train_epochs**: The number of training epochs.\n",
    "\n",
    "-   **batch_size**: Batch size used for training and evaluation.\n",
    "\n",
    "-   **dropout_rate**: Controls the rate of dropout following each fully\n",
    "    connected layer\n",
    "\n",
    "-   **eval_steps**: The number of batches to process before deeming evaluation\n",
    "    is complete. If set to `None`, all instances in the test set are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N03EFEkcOBaJ"
   },
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "  \"\"\"Hyperparameters used for training.\"\"\"\n",
    "  def __init__(self):\n",
    "    ### dataset parameters\n",
    "    # self.num_classes = 7\n",
    "    self.num_classes = 2\n",
    "    self.max_seq_length = 1224 # distinct features\n",
    "    ### neural graph learning parameters\n",
    "    self.distance_type = nsl.configs.DistanceType.L2\n",
    "    self.graph_regularization_multiplier = 0.1\n",
    "    self.num_neighbors = 1\n",
    "    ### model architecture\n",
    "    self.num_fc_units = [50, 50]\n",
    "    ### training parameters\n",
    "    self.train_epochs = 100\n",
    "    self.batch_size = 128\n",
    "    self.dropout_rate = 0.5\n",
    "    ### eval parameters\n",
    "    self.eval_steps = None  # All instances in the test set are evaluated.\n",
    "\n",
    "HPARAMS = HParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IMp34x0MfMMZ"
   },
   "source": [
    "## Load train and test data\n",
    "\n",
    "As described earlier in this notebook, the input training and test data have\n",
    "been created by the **'preprocess_cora_dataset.py'**. We will load them into two\n",
    "`tf.data.Dataset` objects -- one for train and one for test.\n",
    "\n",
    "In the input layer of our model, we will extract not just the 'words' and the\n",
    "'label' features from each sample, but also corresponding neighbor features\n",
    "based on the `hparams.num_neighbors`. Instances with fewer neighbors than\n",
    "`hparams.num_neighbors` will be assigned dummy values for those non-existent\n",
    "neighbor features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCKQVKGee1ST"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function parse_example at 0x638cdbc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function parse_example at 0x638cdbc80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "def parse_example(example_proto):\n",
    "  \"\"\"Extracts relevant fields from the `example_proto`.\n",
    "\n",
    "  Args:\n",
    "    example_proto: An instance of `tf.train.Example`.\n",
    "\n",
    "  Returns:\n",
    "    A pair whose first value is a dictionary containing relevant features\n",
    "    and whose second value contains the ground truth labels.\n",
    "  \"\"\"\n",
    "  # The 'words' feature is a multi-hot, bag-of-words representation of the\n",
    "  # original raw text. A default value is required for examples that don't\n",
    "  # have the feature.\n",
    "  feature_spec = {\n",
    "      'words':\n",
    "          tf.io.FixedLenFeature([HPARAMS.max_seq_length],\n",
    "                                tf.int64,\n",
    "                                default_value=tf.constant(\n",
    "                                    0,\n",
    "                                    dtype=tf.int64,\n",
    "                                    shape=[HPARAMS.max_seq_length])),\n",
    "      'label':\n",
    "          tf.io.FixedLenFeature((), tf.int64, default_value=-1),\n",
    "  }\n",
    "  # We also extract corresponding neighbor features in a similar manner to\n",
    "  # the features above.\n",
    "  for i in range(HPARAMS.num_neighbors):\n",
    "    nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, i, 'words')\n",
    "    nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, i, NBR_WEIGHT_SUFFIX)\n",
    "    feature_spec[nbr_feature_key] = tf.io.FixedLenFeature(\n",
    "        [HPARAMS.max_seq_length],\n",
    "        tf.int64,\n",
    "        default_value=tf.constant(\n",
    "            0, dtype=tf.int64, shape=[HPARAMS.max_seq_length]))\n",
    "\n",
    "    # We assign a default value of 0.0 for the neighbor weight so that\n",
    "    # graph regularization is done on samples based on their exact number\n",
    "    # of neighbors. In other words, non-existent neighbors are discounted.\n",
    "    feature_spec[nbr_weight_key] = tf.io.FixedLenFeature(\n",
    "        [1], tf.float32, default_value=tf.constant([0.0]))\n",
    "\n",
    "  features = tf.io.parse_single_example(example_proto, feature_spec)\n",
    "\n",
    "  labels = features.pop('label')\n",
    "  return features, labels\n",
    "\n",
    "\n",
    "def make_dataset(file_path, training=False):\n",
    "  \"\"\"Creates a `tf.data.TFRecordDataset`.\n",
    "\n",
    "  Args:\n",
    "    file_path: Name of the file in the `.tfrecord` format containing\n",
    "      `tf.train.Example` objects.\n",
    "    training: Boolean indicating if we are in training mode.\n",
    "\n",
    "  Returns:\n",
    "    An instance of `tf.data.TFRecordDataset` containing the `tf.train.Example`\n",
    "    objects.\n",
    "  \"\"\"\n",
    "  dataset = tf.data.TFRecordDataset([file_path])\n",
    "  if training:\n",
    "    dataset = dataset.shuffle(10000)\n",
    "  dataset = dataset.map(parse_example)\n",
    "  dataset = dataset.batch(HPARAMS.batch_size)\n",
    "  return dataset\n",
    "\n",
    "\n",
    "train_dataset = make_dataset(TRAIN_DATA_PATH, training=True)\n",
    "test_dataset = make_dataset(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hEWEGhtVzI2p"
   },
   "source": [
    "Let's peek into the train dataset to look at its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gx-YFaBoCOcl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature list: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
      "Batch of inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1224), dtype=int64)\n",
      "Batch of neighbor inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1224), dtype=int64)\n",
      "Batch of neighbor weights: tf.Tensor(\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.], shape=(128,), dtype=float32)\n",
      "Batch of labels: tf.Tensor(\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_dataset.take(1):\n",
    "  print('Feature list:', list(feature_batch.keys()))\n",
    "  print('Batch of inputs:', feature_batch['words'])\n",
    "  nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, 0, 'words')\n",
    "  nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, 0, NBR_WEIGHT_SUFFIX)\n",
    "  print('Batch of neighbor inputs:', feature_batch[nbr_feature_key])\n",
    "  print('Batch of neighbor weights:',\n",
    "        tf.reshape(feature_batch[nbr_weight_key], [-1]))\n",
    "  print('Batch of labels:', label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7B30hRPzOBE"
   },
   "source": [
    "Let's peek into the test dataset to look at its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNJuM9yJiFtj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature list: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
      "Batch of inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1224), dtype=int64)\n",
      "Batch of neighbor inputs: tf.Tensor(\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], shape=(128, 1224), dtype=int64)\n",
      "Batch of neighbor weights: tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "Batch of labels: tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in test_dataset.take(1):\n",
    "  print('Feature list:', list(feature_batch.keys()))\n",
    "  print('Batch of inputs:', feature_batch['words'])\n",
    "  nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, 0, 'words')\n",
    "  nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, 0, NBR_WEIGHT_SUFFIX)\n",
    "  print('Batch of neighbor inputs:', feature_batch[nbr_feature_key])\n",
    "  print('Batch of neighbor weights:',\n",
    "        tf.reshape(feature_batch[nbr_weight_key], [-1]))\n",
    "  print('Batch of labels:', label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZhsTo8yio8i"
   },
   "source": [
    "## Model definition\n",
    "\n",
    "In order to demonstrate the use of graph regularization, we build a base model\n",
    "for this problem first. We will use a simple feed-forward neural network with 2\n",
    "hidden layers and dropout in between. We illustrate the creation of the base\n",
    "model using all model types supported by the `tf.Keras` framework -- sequential,\n",
    "functional, and subclass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_kBDDfFiuyI"
   },
   "source": [
    "### Sequential base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pecJmegfWijx"
   },
   "outputs": [],
   "source": [
    "def make_mlp_sequential_model(hparams):\n",
    "  \"\"\"Creates a sequential multi-layer perceptron model.\"\"\"\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(\n",
    "      tf.keras.layers.InputLayer(\n",
    "          input_shape=(hparams.max_seq_length,), name='words'))\n",
    "  # Input is already one-hot encoded in the integer format. We cast it to\n",
    "  # floating point format here.\n",
    "  model.add(\n",
    "      tf.keras.layers.Lambda(lambda x: tf.keras.backend.cast(x, tf.float32)))\n",
    "  for num_units in hparams.num_fc_units:\n",
    "    model.add(tf.keras.layers.Dense(num_units, activation='relu'))\n",
    "    # For sequential models, by default, Keras ensures that the 'dropout' layer\n",
    "    # is invoked only during training.\n",
    "    model.add(tf.keras.layers.Dropout(hparams.dropout_rate))\n",
    "  model.add(tf.keras.layers.Dense(hparams.num_classes, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZWxqVPiz_f"
   },
   "source": [
    "### Functional base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TU-YE4NXi7PK"
   },
   "outputs": [],
   "source": [
    "def make_mlp_functional_model(hparams):\n",
    "  \"\"\"Creates a functional API-based multi-layer perceptron model.\"\"\"\n",
    "  inputs = tf.keras.Input(\n",
    "      shape=(hparams.max_seq_length,), dtype='int64', name='words')\n",
    "\n",
    "  # Input is already one-hot encoded in the integer format. We cast it to\n",
    "  # floating point format here.\n",
    "  cur_layer = tf.keras.layers.Lambda(\n",
    "      lambda x: tf.keras.backend.cast(x, tf.float32))(\n",
    "          inputs)\n",
    "\n",
    "  for num_units in hparams.num_fc_units:\n",
    "    cur_layer = tf.keras.layers.Dense(num_units, activation='relu')(cur_layer)\n",
    "    # For functional models, by default, Keras ensures that the 'dropout' layer\n",
    "    # is invoked only during training.\n",
    "    cur_layer = tf.keras.layers.Dropout(hparams.dropout_rate)(cur_layer)\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(\n",
    "      hparams.num_classes, activation='softmax')(\n",
    "          cur_layer)\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs=outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8LmAhITRi8M0"
   },
   "source": [
    "### Subclass base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4l1aK9b_jAw6"
   },
   "outputs": [],
   "source": [
    "def make_mlp_subclass_model(hparams):\n",
    "  \"\"\"Creates a multi-layer perceptron subclass model in Keras.\"\"\"\n",
    "\n",
    "  class MLP(tf.keras.Model):\n",
    "    \"\"\"Subclass model defining a multi-layer perceptron.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "      super(MLP, self).__init__()\n",
    "      # Input is already one-hot encoded in the integer format. We create a\n",
    "      # layer to cast it to floating point format here.\n",
    "      self.cast_to_float_layer = tf.keras.layers.Lambda(\n",
    "          lambda x: tf.keras.backend.cast(x, tf.float32))\n",
    "      self.dense_layers = [\n",
    "          tf.keras.layers.Dense(num_units, activation='relu')\n",
    "          for num_units in hparams.num_fc_units\n",
    "      ]\n",
    "      self.dropout_layer = tf.keras.layers.Dropout(hparams.dropout_rate)\n",
    "      self.output_layer = tf.keras.layers.Dense(\n",
    "          hparams.num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "      cur_layer = self.cast_to_float_layer(inputs['words'])\n",
    "      for dense_layer in self.dense_layers:\n",
    "        cur_layer = dense_layer(cur_layer)\n",
    "        cur_layer = self.dropout_layer(cur_layer, training=training)\n",
    "\n",
    "      outputs = self.output_layer(cur_layer)\n",
    "\n",
    "      return outputs\n",
    "\n",
    "  return MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BbGpIbscjIAo"
   },
   "source": [
    "## Create base model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fzMBxiMGjCO4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "words (InputLayer)           [(None, 1224)]            0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 1224)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                61250     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 63,902\n",
      "Trainable params: 63,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a base MLP model using the functional API.\n",
    "# Alternatively, you can also create a sequential or subclass base model using\n",
    "# the make_mlp_sequential_model() or make_mlp_subclass_model() functions\n",
    "# respectively, defined above. Note that if a subclass model is used, its\n",
    "# summary cannot be generated until it is built.\n",
    "base_model_tag, base_model = 'FUNCTIONAL', make_mlp_functional_model(HPARAMS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T1uEboimjiW7"
   },
   "source": [
    "## Train base (Multilayer perceptron) MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JALapM4PoCvi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x6396bdb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x6396bdb70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.6286 - accuracy: 0.7859\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5799 - accuracy: 0.8174\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5328 - accuracy: 0.8219\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4964 - accuracy: 0.8219\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.4691 - accuracy: 0.8234\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4394 - accuracy: 0.8234\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4157 - accuracy: 0.8219\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.4082 - accuracy: 0.8219\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3827 - accuracy: 0.8263\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3773 - accuracy: 0.8219\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3619 - accuracy: 0.8249\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.3642 - accuracy: 0.8219\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3426 - accuracy: 0.8204\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3423 - accuracy: 0.8278\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3300 - accuracy: 0.8249\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3286 - accuracy: 0.8308\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3193 - accuracy: 0.8234\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3207 - accuracy: 0.8234\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3057 - accuracy: 0.8338\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3074 - accuracy: 0.8263\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2971 - accuracy: 0.8308\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3049 - accuracy: 0.8353\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2934 - accuracy: 0.8338\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2896 - accuracy: 0.8398\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2589 - accuracy: 0.8473\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2708 - accuracy: 0.8458\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2683 - accuracy: 0.8623\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2670 - accuracy: 0.8623\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2605 - accuracy: 0.8668\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2671 - accuracy: 0.8743\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2544 - accuracy: 0.8862\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2520 - accuracy: 0.8757\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2592 - accuracy: 0.8847\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2305 - accuracy: 0.8952\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2355 - accuracy: 0.9027\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2339 - accuracy: 0.9027\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2280 - accuracy: 0.9072\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2222 - accuracy: 0.8997\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2163 - accuracy: 0.9177\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2012 - accuracy: 0.9147\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2056 - accuracy: 0.9237\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2167 - accuracy: 0.9027\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2071 - accuracy: 0.9087\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2075 - accuracy: 0.9251\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1869 - accuracy: 0.9281\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1926 - accuracy: 0.9192\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1929 - accuracy: 0.9371\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1807 - accuracy: 0.9251\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1705 - accuracy: 0.9341\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1827 - accuracy: 0.9311\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1690 - accuracy: 0.9476\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.1787 - accuracy: 0.9311\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1775 - accuracy: 0.9416\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1679 - accuracy: 0.9416\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1696 - accuracy: 0.9311\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1541 - accuracy: 0.9401\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1620 - accuracy: 0.9341\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.1631 - accuracy: 0.9356\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1474 - accuracy: 0.9521\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1631 - accuracy: 0.9401\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1506 - accuracy: 0.9506\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1623 - accuracy: 0.9326\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1834 - accuracy: 0.9251\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1507 - accuracy: 0.9371\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1540 - accuracy: 0.9386\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1660 - accuracy: 0.9251\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1458 - accuracy: 0.9431\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1336 - accuracy: 0.9461\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1371 - accuracy: 0.9446\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1592 - accuracy: 0.9401\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1364 - accuracy: 0.9491\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1519 - accuracy: 0.9356\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1423 - accuracy: 0.9431\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1462 - accuracy: 0.9446\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1540 - accuracy: 0.9326\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1415 - accuracy: 0.9386\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1358 - accuracy: 0.9446\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1459 - accuracy: 0.9371\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1372 - accuracy: 0.9416\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1343 - accuracy: 0.9416\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1336 - accuracy: 0.9326\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1455 - accuracy: 0.9431\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1479 - accuracy: 0.9431\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1286 - accuracy: 0.9476\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1402 - accuracy: 0.9491\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1544 - accuracy: 0.9416\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1324 - accuracy: 0.9491\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1321 - accuracy: 0.9341\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1321 - accuracy: 0.9431\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1286 - accuracy: 0.9536\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1392 - accuracy: 0.9401\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1306 - accuracy: 0.9446\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1262 - accuracy: 0.9431\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1294 - accuracy: 0.9431\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1216 - accuracy: 0.9536\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1373 - accuracy: 0.9326\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1185 - accuracy: 0.9431\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1324 - accuracy: 0.9491\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1190 - accuracy: 0.9521\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1293 - accuracy: 0.9401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x639637f28>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train the base MLP model\n",
    "base_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "base_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPRioqydQD_8"
   },
   "source": [
    "## Evaluate base MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2NcsJVt6FSmZ"
   },
   "outputs": [],
   "source": [
    "# Helper function to print evaluation metrics.\n",
    "def print_metrics(model_desc, eval_metrics):\n",
    "  \"\"\"Prints evaluation metrics.\n",
    "\n",
    "  Args:\n",
    "    model_desc: A description of the model.\n",
    "    eval_metrics: A dictionary mapping metric names to corresponding values. It\n",
    "      must contain the loss and accuracy metrics.\n",
    "  \"\"\"\n",
    "  print('\\n')\n",
    "  print('Eval accuracy for ', model_desc, ': ', eval_metrics['accuracy'])\n",
    "  print('Eval loss for ', model_desc, ': ', eval_metrics['loss'])\n",
    "  if 'graph_loss' in eval_metrics:\n",
    "    print('Eval graph loss for ', model_desc, ': ', eval_metrics['graph_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-myfttwIQAwc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5879 - accuracy: 0.8634\n",
      "\n",
      "\n",
      "Eval accuracy for  Base MLP model :  0.863388\n",
      "Eval loss for  Base MLP model :  0.5878893360495567\n"
     ]
    }
   ],
   "source": [
    "eval_results = dict(\n",
    "    zip(base_model.metrics_names,\n",
    "        base_model.evaluate(test_dataset, steps=HPARAMS.eval_steps)))\n",
    "print_metrics('Base MLP model', eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bGwSzS9Spaiu"
   },
   "source": [
    "## Train MLP model with graph regularization\n",
    "\n",
    "Incorporating graph regularization into the loss term of an existing\n",
    "`tf.Keras.Model` requires just a few lines of code. The base model is wrapped to\n",
    "create a new `tf.Keras` subclass model, whose loss includes graph\n",
    "regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuIGN8KQH0jR"
   },
   "source": [
    "To assess the incremental benefit of graph regularization, we will create a new\n",
    "base model instance. This is because `base_model` has already been trained for a\n",
    "few iterations, and reusing this trained model to create a graph-regularized\n",
    "model will not be a fair comparison for `base_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fvLei9dLCH0"
   },
   "outputs": [],
   "source": [
    "# Build a new base MLP model.\n",
    "base_reg_model_tag, base_reg_model = 'FUNCTIONAL', make_mlp_functional_model(\n",
    "    HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HT3mpC8Lo1UZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method GraphRegularization.call of <neural_structured_learning.keras.graph_regularization.GraphRegularization object at 0x639dc4cc0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method GraphRegularization.call of <neural_structured_learning.keras.graph_regularization.GraphRegularization object at 0x639dc4cc0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /Users/johanweisshansen/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x63aa320d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johanweisshansen/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x63aa320d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johanweisshansen/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 319ms/step - loss: 0.6525 - accuracy: 0.6377 - graph_loss: 0.0199\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.6235 - accuracy: 0.8024 - graph_loss: 0.0228\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.5831 - accuracy: 0.8189 - graph_loss: 0.0278\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5321 - accuracy: 0.8249 - graph_loss: 0.0266\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4975 - accuracy: 0.8234 - graph_loss: 0.0317\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.4665 - accuracy: 0.8293 - graph_loss: 0.0325\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.4432 - accuracy: 0.8278 - graph_loss: 0.0347\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.3978 - accuracy: 0.8293 - graph_loss: 0.0363\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.4043 - accuracy: 0.8249 - graph_loss: 0.0367\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3892 - accuracy: 0.8293 - graph_loss: 0.0423\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3777 - accuracy: 0.8308 - graph_loss: 0.0429\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3736 - accuracy: 0.8308 - graph_loss: 0.0388\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.8353 - graph_loss: 0.0391\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.3640 - accuracy: 0.8338 - graph_loss: 0.0362\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.3359 - accuracy: 0.8383 - graph_loss: 0.0392\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3349 - accuracy: 0.8308 - graph_loss: 0.0418\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3343 - accuracy: 0.8368 - graph_loss: 0.0436\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3078 - accuracy: 0.8533 - graph_loss: 0.0558\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3268 - accuracy: 0.8428 - graph_loss: 0.0527\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3126 - accuracy: 0.8383 - graph_loss: 0.0541\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2984 - accuracy: 0.8458 - graph_loss: 0.0613\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2876 - accuracy: 0.8458 - graph_loss: 0.0660\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2977 - accuracy: 0.8443 - graph_loss: 0.0512\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2879 - accuracy: 0.8533 - graph_loss: 0.0527\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2915 - accuracy: 0.8458 - graph_loss: 0.0507\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2770 - accuracy: 0.8698 - graph_loss: 0.0643\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2659 - accuracy: 0.8713 - graph_loss: 0.0559\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2639 - accuracy: 0.8638 - graph_loss: 0.0761\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2570 - accuracy: 0.8832 - graph_loss: 0.0646\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2634 - accuracy: 0.8743 - graph_loss: 0.0756\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2458 - accuracy: 0.8772 - graph_loss: 0.0739\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2540 - accuracy: 0.8862 - graph_loss: 0.0675\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2479 - accuracy: 0.8877 - graph_loss: 0.0773\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2347 - accuracy: 0.8982 - graph_loss: 0.0865\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2316 - accuracy: 0.9117 - graph_loss: 0.0812\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2456 - accuracy: 0.9057 - graph_loss: 0.0979\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2252 - accuracy: 0.9102 - graph_loss: 0.0908\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2186 - accuracy: 0.9087 - graph_loss: 0.1079\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2184 - accuracy: 0.9087 - graph_loss: 0.1006\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2222 - accuracy: 0.9072 - graph_loss: 0.0948\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2030 - accuracy: 0.9192 - graph_loss: 0.1001\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1999 - accuracy: 0.9222 - graph_loss: 0.1144\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2070 - accuracy: 0.9102 - graph_loss: 0.1029\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2059 - accuracy: 0.9237 - graph_loss: 0.1109\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2008 - accuracy: 0.9147 - graph_loss: 0.1413\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1924 - accuracy: 0.9251 - graph_loss: 0.1364\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1964 - accuracy: 0.9251 - graph_loss: 0.1259\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1929 - accuracy: 0.9266 - graph_loss: 0.1341\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1895 - accuracy: 0.9222 - graph_loss: 0.1302\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1803 - accuracy: 0.9296 - graph_loss: 0.1244\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1895 - accuracy: 0.9266 - graph_loss: 0.1324\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1889 - accuracy: 0.9266 - graph_loss: 0.1286\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1836 - accuracy: 0.9311 - graph_loss: 0.1431\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1816 - accuracy: 0.9356 - graph_loss: 0.1489\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1927 - accuracy: 0.9222 - graph_loss: 0.1519\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1727 - accuracy: 0.9446 - graph_loss: 0.1418\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1744 - accuracy: 0.9326 - graph_loss: 0.1538\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1719 - accuracy: 0.9401 - graph_loss: 0.1472\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1798 - accuracy: 0.9296 - graph_loss: 0.1503\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1695 - accuracy: 0.9401 - graph_loss: 0.1675\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1729 - accuracy: 0.9326 - graph_loss: 0.1708\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1692 - accuracy: 0.9386 - graph_loss: 0.1387\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1801 - accuracy: 0.9356 - graph_loss: 0.1562\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1674 - accuracy: 0.9356 - graph_loss: 0.1622\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1651 - accuracy: 0.9431 - graph_loss: 0.1569\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1743 - accuracy: 0.9356 - graph_loss: 0.1701\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1663 - accuracy: 0.9461 - graph_loss: 0.1652\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1644 - accuracy: 0.9446 - graph_loss: 0.1691\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1680 - accuracy: 0.9371 - graph_loss: 0.1703\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1761 - accuracy: 0.9311 - graph_loss: 0.1695\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1630 - accuracy: 0.9356 - graph_loss: 0.1768\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1594 - accuracy: 0.9326 - graph_loss: 0.1541\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1550 - accuracy: 0.9491 - graph_loss: 0.1676\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1587 - accuracy: 0.9461 - graph_loss: 0.1728\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1546 - accuracy: 0.9476 - graph_loss: 0.1686\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1438 - accuracy: 0.9596 - graph_loss: 0.1908\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1619 - accuracy: 0.9446 - graph_loss: 0.1651\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1480 - accuracy: 0.9521 - graph_loss: 0.1914\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1618 - accuracy: 0.9371 - graph_loss: 0.1945\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1572 - accuracy: 0.9431 - graph_loss: 0.1600\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1408 - accuracy: 0.9431 - graph_loss: 0.1810\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1594 - accuracy: 0.9506 - graph_loss: 0.1644\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1521 - accuracy: 0.9476 - graph_loss: 0.1697\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1600 - accuracy: 0.9446 - graph_loss: 0.1845\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1474 - accuracy: 0.9521 - graph_loss: 0.1867\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1499 - accuracy: 0.9536 - graph_loss: 0.2045\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1524 - accuracy: 0.9401 - graph_loss: 0.1763\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1491 - accuracy: 0.9476 - graph_loss: 0.2030\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1393 - accuracy: 0.9431 - graph_loss: 0.1734\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1418 - accuracy: 0.9551 - graph_loss: 0.1789\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1459 - accuracy: 0.9521 - graph_loss: 0.1937\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1413 - accuracy: 0.9506 - graph_loss: 0.1867\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1416 - accuracy: 0.9476 - graph_loss: 0.1834\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1541 - accuracy: 0.9551 - graph_loss: 0.1969\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1475 - accuracy: 0.9401 - graph_loss: 0.1906\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1443 - accuracy: 0.9566 - graph_loss: 0.1755\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1473 - accuracy: 0.9491 - graph_loss: 0.1810\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1394 - accuracy: 0.9536 - graph_loss: 0.2078\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1407 - accuracy: 0.9446 - graph_loss: 0.1811\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1344 - accuracy: 0.9491 - graph_loss: 0.1947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x639dec6a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap the base MLP model with graph regularization.\n",
    "graph_reg_config = nsl.configs.make_graph_reg_config(\n",
    "    max_neighbors=HPARAMS.num_neighbors,\n",
    "    multiplier=HPARAMS.graph_regularization_multiplier,\n",
    "    distance_type=HPARAMS.distance_type,\n",
    "    sum_over_axis=-1)\n",
    "\n",
    "graph_reg_model = nsl.keras.GraphRegularization(base_reg_model,\n",
    "                                                graph_reg_config)\n",
    "graph_reg_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "graph_reg_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6409ylRVQS7q"
   },
   "source": [
    "## Evaluate MLP model with graph regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TsOE1bAQTqD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 159ms/step - loss: 0.4977 - accuracy: 0.9071 - graph_loss: 0.0000e+00\n",
      "\n",
      "\n",
      "Eval accuracy for  MLP + graph regularization :  0.90710384\n",
      "Eval loss for  MLP + graph regularization :  0.4976902939379215\n",
      "Eval graph loss for  MLP + graph regularization :  0.0\n"
     ]
    }
   ],
   "source": [
    "eval_results = dict(\n",
    "    zip(graph_reg_model.metrics_names,\n",
    "        graph_reg_model.evaluate(test_dataset, steps=HPARAMS.eval_steps)))\n",
    "print_metrics('MLP + graph regularization', eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Adc-r84EOSQi"
   },
   "source": [
    "The graph-regularized model's accuracy is about 2-3% higher than that of the\n",
    "base model (`base_model`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OEXQHFNvJQJe"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "We have demonstrated the use of graph regularization for document classification\n",
    "on a natural citation graph (Cora) using the Neural Structured Learning (NSL)\n",
    "framework. Our [advanced tutorial](graph_keras_lstm_imdb.ipynb) involves\n",
    "synthesizing graphs based on sample embeddings before training a neural network\n",
    "with graph regularization. This approach is useful if the input does not contain\n",
    "an explicit graph.\n",
    "\n",
    "We encourage users to experiment further by varying the amount of supervision as\n",
    "well as trying different neural architectures for graph regularization."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Graph regularization for terror data and relationships using natural graphs",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
